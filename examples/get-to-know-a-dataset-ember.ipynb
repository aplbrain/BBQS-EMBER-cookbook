{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ed3e340-17fd-4b71-a98e-c776aa45d053",
   "metadata": {},
   "source": [
    "# Get to Know a Dataset: EMBER\n",
    "\n",
    "This notebook serves as a guided tour of the [EMBER](https://emberarchive.org) Open Data bucket. EMBER is the Ecosystem for Multi-modal Brain-behavior Experimentation and Research.\n",
    "\n",
    "More usage examples, tutorials, and documentation for this dataset and others can be found at the [Registry of Open Data on AWS](https://registry.opendata.aws/ember)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3779654-eeee-4708-83cf-245e03303475",
   "metadata": {},
   "source": [
    "### Q: How is the EMBER Open Data Bucket organized?\n",
    "\n",
    "To understand the organization of the EMBER Open Data bucket, it's important to understand the organization of an EMBER project.\n",
    "\n",
    "An EMBER project is the top-level organizational unit for EMBER. Within an EMBER project, public data and additional metadata is mostly commonly be stored as dandisets in [EMBER-DANDI](https://dandi.emberarchive.org/). In special cases, EMBER also supports storing other datasets forms.\n",
    "\n",
    "The EMBER Open Data bucket is organized into three sections, as follows:\n",
    "\n",
    "1. [EMBER-dandisets](https://dandi.emberarchive.org/)\n",
    "    - EMBER-dandisets are stored using the prefixes blobs/ and dandisets/\n",
    "2. Other EMBER Data\n",
    "    - Other forms of datasets are stored using the prefix other/\n",
    "3. Tools\n",
    "    - EMBER tools are stored using the prefix tools/\n",
    "\n",
    "\n",
    "For this tutorial, we will demonstrate using 2 EMBER projects:  \n",
    "- [Kumar2025](https://emberarchive.org/project/kumar2025)\n",
    "- [Shepherd2025 - EMBER-DANDI:000463](https://dandi.emberarchive.org/dandiset/000463)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b47b69",
   "metadata": {},
   "source": [
    "First we will import the Python libraries required throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65803f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook requires the following additional libraries\n",
    "# (please install using the preferred method for your environment, e.g. uv, pip, conda):\n",
    "#\n",
    "# \"boto3>=1.42.29\"\n",
    "# \"h5py>=3.15.1\"\n",
    "# \"matplotlib>=3.10.8\"\n",
    "# \"pynwb>=3.1.3\"\n",
    "# \"requests>=2.32.5\"\n",
    "\n",
    "import boto3\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "from pynwb import NWBHDF5IO\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c820c88",
   "metadata": {},
   "source": [
    "Next, we will define the location of our EMBER Open Data Bucket and create our boto3 S3 client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4265826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBER S3 bucket\n",
    "bucket = \"ember-open-data\"\n",
    "\n",
    "# List the top level of the bucket using boto3. Because this is a public bucket, we don't need to sign requests.\n",
    "# Here we set the signature version to unsigned, which is required for public buckets.\n",
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "# Print the items in the top-level prefixes to see all of the different BossDB project datasets\n",
    "for item in s3.list_objects_v2(Bucket=bucket, Delimiter='/')['CommonPrefixes']:\n",
    "    print(item['Prefix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f67631",
   "metadata": {},
   "source": [
    "At the top level of the EMBER Open Data bucket, we see that prefixes correspond to EMBER-dandisets (blobs/ and dandisets/), other datasets (other/), and tools (tools/) as described in the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5137790a",
   "metadata": {},
   "source": [
    "In the code blocks below, we will dive into each EMBER project.\n",
    "\n",
    "**Kumar 2025**\n",
    "- EMBER Open Data bucket S3 Prefix: `other/kumar2025/`\n",
    "- Data can also be accessed through our [EMBER Project File Browser: Kumar2025](https://ember-open-data.s3.us-east-1.amazonaws.com/other/kumar2025/index.html)\n",
    "\n",
    "\n",
    "We will see that data is organized into classifers, pose_files, and videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a62fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kumar2025\n",
    "project = \"kumar2025\"\n",
    "\n",
    "print(f\"Prefixes within the project: /other/{project}\")\n",
    "# List the key prefixes within the top level of the Kumar2025 dataset\n",
    "for item in s3.list_objects_v2(Bucket=bucket, Prefix=f'other/{project}/', Delimiter='/', MaxKeys=10)['CommonPrefixes']:\n",
    "    print(item['Prefix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a896819",
   "metadata": {},
   "source": [
    "**Shepherd 2025 - EMBER-DANDI:000463**\n",
    "- Data can also be accessed through [EMBER-DANDI File Browser: EMBER-DANDI:000463](https://dandi.emberarchive.org/dandiset/000463/draft/files)\n",
    "\n",
    "We will see that data within the dandiset is organized by subject.\n",
    "\n",
    "Please note that the organization of data within a dandiset does not have a direct correspondence to the organization of data within the S3 bucket. In the steps below, we will see how to get the full S3 bucket path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005bca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shepherd 2025 - EMBER-DANDI:000463\n",
    "dandiset = \"000463\"\n",
    "dandiset_version = \"draft\"\n",
    "dandi_api_base = \"https://api-dandi.emberarchive.org/api\"\n",
    "\n",
    "response = requests.get(f\"{dandi_api_base}/dandisets/{dandiset}/versions/{dandiset_version}/assets/paths\")\n",
    "resp_json = response.json()\n",
    "\n",
    "paths = set()\n",
    "for asset_file in resp_json[\"results\"]:\n",
    "    paths.add(asset_file[\"path\"])\n",
    "\n",
    "paths = sorted(paths)\n",
    "\n",
    "for path in paths[:10]:\n",
    "    print(path)\n",
    "print(\"... (only listing the first 10 paths)\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de073d3c",
   "metadata": {},
   "source": [
    "### Q: What data formats are present in your dataset? What kinds of data are stored using these formats? Can you give any advice for how you work with these data formats?\n",
    "\n",
    "EMBER is the data archive for multimodal neurophysiological and behavioral datasets.\n",
    "\n",
    "Data in our datasets are stored as a set of assets, organized into EMBER-Dandisets. You can find documenation at https://emberarchive.org/documentation.\n",
    "\n",
    "The landing page of each EMBER-Dandiset contains important information including metadata provided by the owners such as contact information, description, license, access information and keywords, simple statistics such as size and number of files, or a summary of the Dandiset including information about species, techniques, and standards.\n",
    "\n",
    "Data within a dataset are organized in one of two ways. First, assets may be organized via the BIDS standard (https://bids.neuroimaging.io/index.html) and can be accessed via the pybids library (https://github.com/bids-standard/pybids). They can also be organized as Neurodata Without Borders files (https://nwb.org/) which is an hdf5-based format for hierarchical physiological data. This can be accessed via (https://pynwb.readthedocs.io/en/stable/). Note that BIDS datasets can sometimes contain NWB files in subdirectories, so both libraries may need to be used in tandem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b914b897",
   "metadata": {},
   "source": [
    "### Q: Can you show us an example of downloading and loading data from your dataset?\n",
    "\n",
    "As an example, we will load a data file from each project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5584a4be",
   "metadata": {},
   "source": [
    "**Kumar 2025**\n",
    "\n",
    "We will look at a single HDF5 file stored in this project.\n",
    "\n",
    "- Data can also be browsed through our [EMBER Project File Browser: Kumar2025](https://ember-open-data.s3.us-east-1.amazonaws.com/other/kumar2025/index.html#pose_files%2F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac827410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kumar 2025\n",
    "\n",
    "print(f\"\\nList of files in: /other/{project}/pose_files\")\n",
    "# List files within other/kumar2025/pose_files/\n",
    "objects = s3.list_objects_v2(Bucket=bucket, Prefix=f'other/{project}/pose_files/', Delimiter='/', MaxKeys=10)['Contents']\n",
    "for item in objects:\n",
    "    print(item['Key'])\n",
    "print(\"... (only listing the first 10 files)\\n\")\n",
    "\n",
    "# Select 1 HDF5 file to explore further\n",
    "h5_path = objects[0]['Key']\n",
    "local_h5_file = f\"kumar2025-{h5_path.split(\"/\")[-1]}\"\n",
    "\n",
    "# Download the file\n",
    "s3.download_file(bucket, h5_path, local_h5_file)\n",
    "print(f\"Downloaded local file:\\n\\t{local_h5_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2005f59d",
   "metadata": {},
   "source": [
    "**Shepherd 2025 - EMBER-DANDI:000463**\n",
    "\n",
    "We will look at a single NWB file stored in this dandiset.\n",
    "\n",
    "We will see that data files can be accessed directly via S3 or using the EMBER-DANDI API:\n",
    "- https://ember-open-data.s3.amazonaws.com/blobs/a67/f98/a67f98c3-ffb8-4c40-8b2f-45706e6bf8a9\n",
    "- https://api-dandi.emberarchive.org/api/assets/2d0c4695-a091-48c3-b70c-61b5567ef515/download/\n",
    "- Data can also be browsed through the [EMBER-DANDI File Browser](https://dandi.emberarchive.org/dandiset/000463/draft/files?location=sub-ADPTM01)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545187bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shepherd 2025 - EMBER-DANDI:000463\n",
    "\n",
    "# Use the first file path from above\n",
    "file_path = paths[0]\n",
    "\n",
    "# Query Dandiset assets for files witht the above file path\n",
    "response = requests.get(f\"{dandi_api_base}/dandisets/{dandiset}/versions/{dandiset_version}/assets/?path={file_path}&metadata=false&zarr=false\")\n",
    "\n",
    "# Filter out non-NWB files (for this demo)\n",
    "assets = response.json()[\"results\"]\n",
    "nwb_assets = [asset for asset in assets if \".nwb\" in  asset[\"path\"]]\n",
    "\n",
    "# Select 1 NWB file to explore further\n",
    "file = nwb_assets[0]\n",
    "asset_id = file[\"asset_id\"]\n",
    "print(f\"Asset Path:\\n\\t{file[\"path\"]}\")\n",
    "\n",
    "# Get asset metadata\n",
    "asset_response = requests.get(f\"{dandi_api_base}/dandisets/{dandiset}/versions/{dandiset_version}/assets/{asset_id}\")\n",
    "asset_access_urls = asset_response.json()[\"contentUrl\"]\n",
    "\n",
    "print(\"Asset Access Methods:\")\n",
    "for access_method in asset_access_urls:\n",
    "    print(f\"\\t{access_method}\")\n",
    "\n",
    "# Get S3 Access URL\n",
    "s3_access_url = asset_access_urls[1]\n",
    "# Strip the S3 URL to get the prefix path\n",
    "s3_path = urlparse(s3_access_url).path.lstrip(\"/\")\n",
    "local_nwb_file = f\"dandiset000463-{file[\"path\"].split(\"/\")[-1]}\"\n",
    "\n",
    "# Download the file\n",
    "s3.download_file(bucket, s3_path, local_nwb_file)\n",
    "print(f\"Downloaded local file:\\n\\t{local_nwb_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3e3585",
   "metadata": {},
   "source": [
    "Now, we will read some basic information from the files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ae6b69",
   "metadata": {},
   "source": [
    "**Kumar 2025**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af196e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kumar 2025\n",
    "\n",
    "# Open the HDF5 file\n",
    "with h5py.File(local_h5_file, \"r\") as f:\n",
    "    print(\"Top-level keys (groups):\", list(f.keys()))\n",
    "\n",
    "    def show_h5(name, obj):\n",
    "        if isinstance(obj, h5py.Dataset):\n",
    "            print(f\"  DATASET {name} shape={obj.shape}\")\n",
    "        else:\n",
    "            print(f\"GROUP   {name}\")\n",
    "\n",
    "    # Print each Group and Dataset\n",
    "    f.visititems(show_h5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c74bd0",
   "metadata": {},
   "source": [
    "**Shepherd 2025 - EMBER-DANDI:000463**\n",
    "\n",
    "NWB Files can also be accessed and explored through [EMBER-DANDI File Browser: EMBER-DANDI:000463](https://dandi.emberarchive.org/dandiset/000463/draft/files?location=sub-ADPTM01)\n",
    "\n",
    "- Select \"Open With\" and then select one of:\n",
    "    - \"Neurosift\"\n",
    "        - [Neurosift](https://neurosift.app/) is a browser-based tool designed for visualizing neuroscience data with a focus on NWB files.\n",
    "        - Example: https://neurosift.app/nwb?url=https://api-dandi.emberarchive.org/api/assets/2d0c4695-a091-48c3-b70c-61b5567ef515/download/&dandisetId=000463&dandisetVersion=draft\n",
    "    - \"MetaCell/NWBExplorer\"\n",
    "        - [NWB Explorer](https://nwbexplorer.v2.opensourcebrain.org/) is a browser-based tool for visualizing and understanding neurophysiology data formatted as an NWB file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9ec8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shepherd 2025 - EMBER-DANDI:000463\n",
    "\n",
    "# Open the NWB file\n",
    "with NWBHDF5IO(local_nwb_file, \"r\") as io:\n",
    "    nwbfile = io.read()\n",
    "\n",
    "    print(\"Session description:\", nwbfile.session_description)\n",
    "    print(\"Start time:\", nwbfile.session_start_time)\n",
    "\n",
    "    print(\"\\nWhatâ€™s in this file?\")\n",
    "    print(\"  Acquisition:\\t\", list(nwbfile.acquisition.keys()))\n",
    "    print(\"  Processing:\\t\", list(nwbfile.processing.keys()))\n",
    "    print(\"  Intervals:\\t\", list(nwbfile.intervals.keys()))\n",
    "    print(\"  Stimulus:\\t\", list(nwbfile.stimulus.keys()))\n",
    "    print(\"  Analysis:\\t\", list(nwbfile.analysis.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505c06e2",
   "metadata": {},
   "source": [
    "To learn more about NWB, please see the following links:\n",
    "\n",
    "- NWB overview: https://nwb.org/\n",
    "- PyNWB documentation: https://pynwb.readthedocs.io/\n",
    "- PyNWB tutorials: https://pynwb.readthedocs.io/en/stable/tutorials/index.html\n",
    "- Common NWB structures: https://pynwb.readthedocs.io/en/stable/tutorials/domain.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42c72c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5da92cf1",
   "metadata": {},
   "source": [
    "### Q: A picture is worth a thousand words. Show us a visual (or several!) from your dataset that either illustrates something informative about your dataset, or that you think might excite someone to dig in further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e487d1",
   "metadata": {},
   "source": [
    "\n",
    "**Shepherd 2025 - EMBER-DANDI:000463**\n",
    "\n",
    "This figure visualizes pose-estimation data from the NWB file, showing how a tracked body point moves over time. The time axis is reconstructed from the sampling rate stored in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd3406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shepherd 2025 - EMBER-DANDI:000463\n",
    "\n",
    "# Open the NWB file\n",
    "with NWBHDF5IO(local_nwb_file, \"r\") as io:\n",
    "    nwbfile = io.read()\n",
    "\n",
    "    pose = nwbfile.processing[\"behavior\"].data_interfaces[\"PoseEstimationDeepLabCut\"]\n",
    "\n",
    "    print(\"Series:\", list(pose.pose_estimation_series))\n",
    "\n",
    "    # Pick the first pose-estimation series\n",
    "    series_name = list(pose.pose_estimation_series.keys())[0]\n",
    "    series = pose.pose_estimation_series[series_name]\n",
    "\n",
    "    print(\"Using series:\", series_name)\n",
    "    print(\"Data shape:\", series.data.shape)\n",
    "\n",
    "    # How many samples to plot\n",
    "    n = min(2000, series.data.shape[0])\n",
    "    xy = np.array(series.data[:n])\n",
    "\n",
    "    # Build time axis from sampling rate\n",
    "    rate = series.rate\n",
    "    starting_time = series.starting_time if series.starting_time is not None else 0.0\n",
    "    t = starting_time + np.arange(n) / rate\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(t, xy[:, 0], label=\"x\")\n",
    "    plt.plot(t, xy[:, 1], label=\"y\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Position\")\n",
    "    plt.title(series.name)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab227ab7",
   "metadata": {},
   "source": [
    "### Q: What is one question that you have answered using these data? Can you show us how you came to that answer?\n",
    "\n",
    "The EMBER Archive is a new effort to support the NIH [Brian Behavior Quantification and Synchronization](https://braininitiative.nih.gov/research/systems-neuroscience/brain-behavior-quantification-and-synchronization-program) program, which is still ongoing. Currently, teams are working on collecting, sharing, and publishing their findings.\n",
    "\n",
    "In the example Shepherd 2025 EMBER-dandiset, the research team investigated dexterous single sniffs for ethological active olfaction. This is to say, they investigated the links between olfaction and movement during feeding in mice, giving novel insight into the link between sensing and behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d20a5b",
   "metadata": {},
   "source": [
    "### Q: What is one unanswered question that you think could be answered using these data? Do you have any recommendations or advice for someone wanting to answer this question?\n",
    "\n",
    "In the NIH [Brian Behavior Quantification and Synchronization](https://braininitiative.nih.gov/research/systems-neuroscience/brain-behavior-quantification-and-synchronization-program) program, the core question is what are the common substrates which underly the neural representation of behavior, and how can these be quantified and represented. Key questions include how everyday activities (navigation, exploration, interaction with the world and others) generate repeatable patterns of neural activity. In addition, there is interest in how neurological disease alters or perturbs this function. Integrating multi-lab and multi-species datasets to give insight into this is a key issue moving forward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422bf7dc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbqs-ember-cookbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
