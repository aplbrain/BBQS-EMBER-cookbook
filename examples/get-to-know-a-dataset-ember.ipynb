{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ed3e340-17fd-4b71-a98e-c776aa45d053",
   "metadata": {},
   "source": [
    "# Get to Know a Dataset: EMBER\n",
    "\n",
    "This notebook serves as a guided tour of th [EMBER](https://emberarchive.org) Open Data bucket. EMBER is the Ecosystem for Multi-modal Brain-behavior Experimentation and Research.\n",
    "\n",
    "More usage examples, tutorials, and documentation for this dataset and others can be found at the [Registry of Open Data on AWS](https://registry.opendata.aws/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3779654-eeee-4708-83cf-245e03303475",
   "metadata": {},
   "source": [
    "### Q: How is the EMBER Open Data Bucket organized?\n",
    "\n",
    "To understand the organization of the EMBER Open Data bucket, it's important to understand the organization of an EMBER project.\n",
    "\n",
    "An EMBER project is the top-level organizational unit for EMBER. Within an EMBER project, public data and additional metadata is mostly commonly be stored as dandisets in [EMBER-DANDI](https://dandi.emberarchive.org/). In special cases, EMBER also supports storing other datasets forms.\n",
    "\n",
    "The EMBER Open Data bucket is organized into three sections, as follows:\n",
    "\n",
    "1. [EMBER-DANDI](https://dandi.emberarchive.org/) dandisets\n",
    "    - EMBER-DANDI dandisets are stored using the prefixes blobs/ and dandisets/\n",
    "2. Other EMBER Data\n",
    "    - Other forms of datasets are stored using the prefix other/\n",
    "3. Tools\n",
    "    - EMBER tools are stored using the prefix tools/\n",
    "\n",
    "\n",
    "For this tutorial, we will demonstrate using 2 EMBER projects:  \n",
    "- [Kumar2025](https://emberarchive.org/project/kumar2025)\n",
    "- [Shepherd2025 - Dandiset 000463](https://dandi.emberarchive.org/dandiset/000463)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b47b69",
   "metadata": {},
   "source": [
    "First we will import the Python libraries required throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65803f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook requires the following additional libraries\n",
    "# (please install using the preferred method for your environment, e.g. uv, pip, conda):\n",
    "#\n",
    "# \"boto3>=1.42.29\",\n",
    "# \"pynwb>=3.1.3\",\n",
    "# \"requests>=2.32.5\",\n",
    "\n",
    "import boto3\n",
    "import requests\n",
    "\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "from pynwb import NWBHDF5IO, NWBFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c820c88",
   "metadata": {},
   "source": [
    "Next, we will define the location of our EMBER Open Data Bucket and create our boto3 S3 client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4265826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBER S3 bucket\n",
    "bucket = \"ember-open-data\"\n",
    "\n",
    "# List the top level of the bucket using boto3. Because this is a public bucket, we don't need to sign requests.\n",
    "# Here we set the signature version to unsigned, which is required for public buckets.\n",
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "# Print the items in the top-level prefixes to see all of the different BossDB project datasets\n",
    "for item in s3.list_objects_v2(Bucket=bucket, Delimiter='/')['CommonPrefixes']:\n",
    "    print(item['Prefix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f67631",
   "metadata": {},
   "source": [
    "At the top level of the EMBER Open Data bucket, we see that prefixes correspond to EMBER-DANDI dandisets (blobs/ and dandisets/), other datasets (other/), and tools (tools/) as described in the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5137790a",
   "metadata": {},
   "source": [
    "In the code blocks below, we will dive into each EMBER project.\n",
    "\n",
    "**Kumar 2025**\n",
    "- EMBER Open Data bucket S3 Prefix: `other/kumar2025/`\n",
    "- Data can also be accessed through our [EMBER Project File Browser: Kumar2025](https://ember-open-data.s3.us-east-1.amazonaws.com/other/kumar2025/index.html)\n",
    "\n",
    "\n",
    "We will see that data is organized into classifers, pose_files, and videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a62fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kumar2025\n",
    "project = \"kumar2025\"\n",
    "\n",
    "# List the key prefixes within the top level of the Kumar2025 dataset\n",
    "for item in s3.list_objects_v2(Bucket=bucket, Prefix=f'other/{project}/', Delimiter='/', MaxKeys=10)['CommonPrefixes']:\n",
    "    print(item['Prefix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a896819",
   "metadata": {},
   "source": [
    "**Shepherd 2025 - Dandiset 000463**\n",
    "- Data can also be accessed through [EMBER-DANDI File Browser: Dandiset 000463](https://dandi.emberarchive.org/dandiset/000463/draft/files)\n",
    "\n",
    "We will see that data within the dandiset is organized by subject.\n",
    "\n",
    "Please note that the organization of data within a dandiset does not have a direct correspondence to the organization of data within the S3 bucket. In the steps below, we will see how to get the full S3 bucket path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005bca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dandiset 000463\n",
    "dandiset = \"000463\"\n",
    "dandiset_version = \"draft\"\n",
    "dandi_api_base = \"https://api-dandi.emberarchive.org/api\"\n",
    "\n",
    "response = requests.get(f\"{dandi_api_base}/dandisets/{dandiset}/versions/{dandiset_version}/assets/paths\")\n",
    "resp_json = response.json()\n",
    "\n",
    "paths = set()\n",
    "for asset_file in resp_json[\"results\"]:\n",
    "    paths.add(asset_file[\"path\"])\n",
    "\n",
    "paths = sorted(paths)\n",
    "for path in paths:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de073d3c",
   "metadata": {},
   "source": [
    "### Q: What data formats are present in your dataset? What kinds of data are stored using these formats? Can you give any advice for how you work with these data formats?\n",
    "\n",
    "EMBER is the data archive for multimodal neurophysiological and behavioral datasets.\n",
    "\n",
    "\n",
    "# TODO !\n",
    "\n",
    "\n",
    "NWB\n",
    "BIDs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b914b897",
   "metadata": {},
   "source": [
    "### Q: Can you show us an example of downloading and loading data from your dataset?\n",
    "\n",
    "As an example, we will load a data file from each project\n",
    "\n",
    "\n",
    "**Shepherd 2025 - Dandiset 000463**\n",
    "- Data can also be accessed through [EMBER-DANDI File Browser: Dandiset 000463](https://dandi.emberarchive.org/dandiset/000463/draft/files?location=sub-ADPTM01).\n",
    "\n",
    "We will see that data files can be accessed using the EMBER-DANDI API or directly via S3:\n",
    "- https://api-dandi.emberarchive.org/api/assets/2d0c4695-a091-48c3-b70c-61b5567ef515/download/\n",
    "- https://ember-open-data.s3.amazonaws.com/blobs/a67/f98/a67f98c3-ffb8-4c40-8b2f-45706e6bf8a9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac827410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kumar 2025\n",
    "\n",
    "# TODO !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545187bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shepherd 2025 - Dandiset 000463\n",
    "\n",
    "# Use the first file path from above\n",
    "file_path = paths[0]\n",
    "\n",
    "# Query Dandiset assets for files witht the above file path\n",
    "response = requests.get(f\"{dandi_api_base}/dandisets/{dandiset}/versions/{dandiset_version}/assets/?path={file_path}&metadata=false&zarr=false\")\n",
    "\n",
    "# Filter out non-NWB files (for this demo)\n",
    "assets = response.json()[\"results\"]\n",
    "nwb_assets = [asset for asset in assets if \".nwb\" in  asset[\"path\"]]\n",
    "\n",
    "# Select 1 NWB file to explore further\n",
    "file = nwb_assets[0]\n",
    "asset_id = file[\"asset_id\"]\n",
    "print(f\"Asset Path:\\n\\t{file[\"path\"]}\")\n",
    "\n",
    "# Get asset metadata\n",
    "asset_response = requests.get(f\"{dandi_api_base}/dandisets/{dandiset}/versions/{dandiset_version}/assets/{asset_id}\")\n",
    "asset_access_urls = asset_response.json()[\"contentUrl\"]\n",
    "\n",
    "print(f\"Asset Access Methods:\")\n",
    "for access_method in asset_access_urls:\n",
    "    print(f\"\\t{access_method}\")\n",
    "\n",
    "# Get S3 Access URL\n",
    "s3_access_url = asset_access_urls[1]\n",
    "local_file = file[\"path\"].split(\"/\")[-1]\n",
    "\n",
    "# Get File contents\n",
    "resp = requests.get(s3_access_url)\n",
    "with open(local_file, \"wb\") as f:\n",
    "    f.write(resp.content)\n",
    "\n",
    "# Open the NWB file\n",
    "with NWBHDF5IO(local_file, \"r\") as io:\n",
    "    nwbfile = io.read()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbqs-ember-cookbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
